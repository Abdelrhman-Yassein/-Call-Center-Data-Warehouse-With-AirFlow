[2022-11-18T23:43:25.066+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [queued]>
[2022-11-18T23:43:25.239+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [queued]>
[2022-11-18T23:43:25.287+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-11-18T23:43:25.310+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2022-11-18T23:43:25.319+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-11-18T23:43:25.772+0000] {taskinstance.py:1383} INFO - Executing <Task(MySqlOperator): load_data_to_staging_call_table> on 2022-11-18 00:00:00+00:00
[2022-11-18T23:43:25.919+0000] {standard_task_runner.py:55} INFO - Started process 1439 to run task
[2022-11-18T23:43:25.969+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'Call_Center_ETL_DAG', 'load_data_to_staging_call_table', 'scheduled__2022-11-18T00:00:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/create_database_tables.py', '--cfg-path', '/tmp/tmp5o98x8k5']
[2022-11-18T23:43:26.038+0000] {standard_task_runner.py:83} INFO - Job 12: Subtask load_data_to_staging_call_table
[2022-11-18T23:43:27.773+0000] {task_command.py:376} INFO - Running <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [running]> on host b6a63ce50866
[2022-11-18T23:43:28.810+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Abdelrhman Yassein
AIRFLOW_CTX_DAG_ID=Call_Center_ETL_DAG
AIRFLOW_CTX_TASK_ID=load_data_to_staging_call_table
AIRFLOW_CTX_EXECUTION_DATE=2022-11-18T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-18T00:00:00+00:00
[2022-11-18T23:43:28.813+0000] {mysql.py:84} INFO - Executing: 
            SET GLOBAL local_infile=1;
            LOAD DATA LOCAL INFILE 'G:/docker-files/CallCenter.csv'
            INTO TABLE staging_call
            COLUMNS TERMINATED BY ','
            OPTIONALLY ENCLOSED BY '"'
            ESCAPED BY '"'
            LINES TERMINATED BY '
'
            IGNORE 1 LINES;
            
[2022-11-18T23:43:29.001+0000] {base.py:71} INFO - Using connection ID 'mysql_conn_id' for task execution.
[2022-11-18T23:43:29.192+0000] {sql.py:315} INFO - Running statement: 
            SET GLOBAL local_infile=1;
            LOAD DATA LOCAL INFILE 'G:/docker-files/CallCenter.csv'
            INTO TABLE staging_call
            COLUMNS TERMINATED BY ','
            OPTIONALLY ENCLOSED BY '"'
            ESCAPED BY '"'
            LINES TERMINATED BY '
'
            IGNORE 1 LINES;
            , parameters: None
[2022-11-18T23:43:29.206+0000] {sql.py:324} INFO - Rows affected: 0
[2022-11-18T23:43:29.220+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/mysql/operators/mysql.py", line 86, in execute
    hook.run(self.sql, autocommit=self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 299, in run
    results.append(result)
  File "/usr/local/lib/python3.7/contextlib.py", line 298, in __exit__
    self.thing.close()
  File "/home/airflow/.local/lib/python3.7/site-packages/MySQLdb/cursors.py", line 83, in close
    while self.nextset():
  File "/home/airflow/.local/lib/python3.7/site-packages/MySQLdb/cursors.py", line 137, in nextset
    nr = db.next_result()
MySQLdb.OperationalError: (2068, 'LOAD DATA LOCAL INFILE file request rejected due to restrictions on access.')
[2022-11-18T23:43:29.262+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=Call_Center_ETL_DAG, task_id=load_data_to_staging_call_table, execution_date=20221118T000000, start_date=20221118T234325, end_date=20221118T234329
[2022-11-18T23:43:29.382+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 12 for task load_data_to_staging_call_table ((2068, 'LOAD DATA LOCAL INFILE file request rejected due to restrictions on access.'); 1439)
[2022-11-18T23:43:29.547+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2022-11-18T23:43:29.839+0000] {taskinstance.py:2623} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-11-19T00:23:01.843+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [queued]>
[2022-11-19T00:23:02.201+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [queued]>
[2022-11-19T00:23:02.210+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-11-19T00:23:02.212+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2022-11-19T00:23:02.213+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-11-19T00:23:02.798+0000] {taskinstance.py:1383} INFO - Executing <Task(MySqlOperator): load_data_to_staging_call_table> on 2022-11-18 00:00:00+00:00
[2022-11-19T00:23:02.946+0000] {standard_task_runner.py:55} INFO - Started process 2832 to run task
[2022-11-19T00:23:03.018+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'Call_Center_ETL_DAG', 'load_data_to_staging_call_table', 'scheduled__2022-11-18T00:00:00+00:00', '--job-id', '35', '--raw', '--subdir', 'DAGS_FOLDER/create_database_tables.py', '--cfg-path', '/tmp/tmpuqvwewhc']
[2022-11-19T00:23:03.095+0000] {standard_task_runner.py:83} INFO - Job 35: Subtask load_data_to_staging_call_table
[2022-11-19T00:23:05.951+0000] {task_command.py:376} INFO - Running <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [running]> on host b6a63ce50866
[2022-11-19T00:23:07.846+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Abdelrhman Yassein
AIRFLOW_CTX_DAG_ID=Call_Center_ETL_DAG
AIRFLOW_CTX_TASK_ID=load_data_to_staging_call_table
AIRFLOW_CTX_EXECUTION_DATE=2022-11-18T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-18T00:00:00+00:00
[2022-11-19T00:23:07.848+0000] {mysql.py:84} INFO - Executing: 
            LOAD DATA LOCAL INFILE 'G:/docker-files/CallCenter.csv'
            INTO TABLE staging_call
            COLUMNS TERMINATED BY ','
            OPTIONALLY ENCLOSED BY '"'
            ESCAPED BY '"'
            LINES TERMINATED BY '
'
            IGNORE 1 LINES;
            
[2022-11-19T00:23:08.156+0000] {base.py:71} INFO - Using connection ID 'mysql_conn_id' for task execution.
[2022-11-19T00:23:08.998+0000] {sql.py:315} INFO - Running statement: 
            LOAD DATA LOCAL INFILE 'G:/docker-files/CallCenter.csv'
            INTO TABLE staging_call
            COLUMNS TERMINATED BY ','
            OPTIONALLY ENCLOSED BY '"'
            ESCAPED BY '"'
            LINES TERMINATED BY '
'
            IGNORE 1 LINES;
            , parameters: None
[2022-11-19T00:23:09.035+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/mysql/operators/mysql.py", line 86, in execute
    hook.run(self.sql, autocommit=self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 295, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 320, in _run_command
    cur.execute(sql_statement)
  File "/home/airflow/.local/lib/python3.7/site-packages/MySQLdb/cursors.py", line 206, in execute
    res = self._query(query)
  File "/home/airflow/.local/lib/python3.7/site-packages/MySQLdb/cursors.py", line 319, in _query
    db.query(q)
  File "/home/airflow/.local/lib/python3.7/site-packages/MySQLdb/connections.py", line 254, in query
    _mysql.connection.query(self, query)
MySQLdb.OperationalError: (2068, 'LOAD DATA LOCAL INFILE file request rejected due to restrictions on access.')
[2022-11-19T00:23:09.397+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=Call_Center_ETL_DAG, task_id=load_data_to_staging_call_table, execution_date=20221118T000000, start_date=20221119T002301, end_date=20221119T002309
[2022-11-19T00:23:09.603+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 35 for task load_data_to_staging_call_table ((2068, 'LOAD DATA LOCAL INFILE file request rejected due to restrictions on access.'); 2832)
[2022-11-19T00:23:09.903+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2022-11-19T00:23:10.186+0000] {taskinstance.py:2623} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-11-19T12:12:58.229+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [queued]>
[2022-11-19T12:12:58.253+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [queued]>
[2022-11-19T12:12:58.254+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-11-19T12:12:58.256+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2022-11-19T12:12:58.257+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-11-19T12:12:58.289+0000] {taskinstance.py:1383} INFO - Executing <Task(MySqlOperator): load_data_to_staging_call_table> on 2022-11-18 00:00:00+00:00
[2022-11-19T12:12:58.299+0000] {standard_task_runner.py:55} INFO - Started process 133 to run task
[2022-11-19T12:12:58.306+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'Call_Center_ETL_DAG', 'load_data_to_staging_call_table', 'scheduled__2022-11-18T00:00:00+00:00', '--job-id', '86', '--raw', '--subdir', 'DAGS_FOLDER/create_database_tables.py', '--cfg-path', '/tmp/tmpggyl9zx0']
[2022-11-19T12:12:58.308+0000] {standard_task_runner.py:83} INFO - Job 86: Subtask load_data_to_staging_call_table
[2022-11-19T12:12:58.458+0000] {task_command.py:376} INFO - Running <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [running]> on host 6e77c1f44c06
[2022-11-19T12:12:58.584+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Abdelrhman Yassein
AIRFLOW_CTX_DAG_ID=Call_Center_ETL_DAG
AIRFLOW_CTX_TASK_ID=load_data_to_staging_call_table
AIRFLOW_CTX_EXECUTION_DATE=2022-11-18T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-18T00:00:00+00:00
[2022-11-19T12:12:58.587+0000] {mysql.py:84} INFO - Executing: 
            LOAD DATA INFILE 'G:/docker-files/CallCenter.csv'
            INTO TABLE staging_call
            COLUMNS TERMINATED BY ','
            OPTIONALLY ENCLOSED BY '"'
            ESCAPED BY '"'
            LINES TERMINATED BY '
'
            IGNORE 1 LINES;
            
[2022-11-19T12:12:58.604+0000] {base.py:71} INFO - Using connection ID 'mysql_conn_id' for task execution.
[2022-11-19T12:12:58.662+0000] {sql.py:315} INFO - Running statement: 
            LOAD DATA INFILE 'G:/docker-files/CallCenter.csv'
            INTO TABLE staging_call
            COLUMNS TERMINATED BY ','
            OPTIONALLY ENCLOSED BY '"'
            ESCAPED BY '"'
            LINES TERMINATED BY '
'
            IGNORE 1 LINES;
            , parameters: None
[2022-11-19T12:12:58.669+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/mysql/operators/mysql.py", line 86, in execute
    hook.run(self.sql, autocommit=self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 295, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 320, in _run_command
    cur.execute(sql_statement)
  File "/home/airflow/.local/lib/python3.7/site-packages/MySQLdb/cursors.py", line 206, in execute
    res = self._query(query)
  File "/home/airflow/.local/lib/python3.7/site-packages/MySQLdb/cursors.py", line 319, in _query
    db.query(q)
  File "/home/airflow/.local/lib/python3.7/site-packages/MySQLdb/connections.py", line 254, in query
    _mysql.connection.query(self, query)
MySQLdb.OperationalError: (1290, 'The MySQL server is running with the --secure-file-priv option so it cannot execute this statement')
[2022-11-19T12:12:58.700+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=Call_Center_ETL_DAG, task_id=load_data_to_staging_call_table, execution_date=20221118T000000, start_date=20221119T121258, end_date=20221119T121258
[2022-11-19T12:12:58.779+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 86 for task load_data_to_staging_call_table ((1290, 'The MySQL server is running with the --secure-file-priv option so it cannot execute this statement'); 133)
[2022-11-19T12:12:58.844+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2022-11-19T12:12:58.877+0000] {taskinstance.py:2623} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-11-19T12:27:13.823+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [queued]>
[2022-11-19T12:27:15.828+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [queued]>
[2022-11-19T12:27:15.988+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-11-19T12:27:16.198+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2022-11-19T12:27:16.467+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-11-19T12:27:19.510+0000] {taskinstance.py:1383} INFO - Executing <Task(MySqlOperator): load_data_to_staging_call_table> on 2022-11-18 00:00:00+00:00
[2022-11-19T12:27:20.461+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'Call_Center_ETL_DAG', 'load_data_to_staging_call_table', 'scheduled__2022-11-18T00:00:00+00:00', '--job-id', '91', '--raw', '--subdir', 'DAGS_FOLDER/create_database_tables.py', '--cfg-path', '/tmp/tmp6ev5dy0g']
[2022-11-19T12:27:20.639+0000] {standard_task_runner.py:83} INFO - Job 91: Subtask load_data_to_staging_call_table
[2022-11-19T12:27:19.919+0000] {standard_task_runner.py:55} INFO - Started process 651 to run task
[2022-11-19T12:27:29.621+0000] {task_command.py:376} INFO - Running <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [running]> on host 6e77c1f44c06
[2022-11-19T12:27:38.326+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Abdelrhman Yassein
AIRFLOW_CTX_DAG_ID=Call_Center_ETL_DAG
AIRFLOW_CTX_TASK_ID=load_data_to_staging_call_table
AIRFLOW_CTX_EXECUTION_DATE=2022-11-18T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-18T00:00:00+00:00
[2022-11-19T12:27:38.581+0000] {mysql.py:84} INFO - Executing: 
            LOAD DATA INFILE 'G:/docker-files/CallCenter.csv'
            INTO TABLE staging_call
            COLUMNS TERMINATED BY ','
            OPTIONALLY ENCLOSED BY '"'
            ESCAPED BY '"'
            LINES TERMINATED BY '
'
            IGNORE 1 LINES;
            
[2022-11-19T12:27:39.525+0000] {base.py:71} INFO - Using connection ID 'mysql_conn_id' for task execution.
[2022-11-19T12:27:43.033+0000] {sql.py:315} INFO - Running statement: 
            LOAD DATA INFILE 'G:/docker-files/CallCenter.csv'
            INTO TABLE staging_call
            COLUMNS TERMINATED BY ','
            OPTIONALLY ENCLOSED BY '"'
            ESCAPED BY '"'
            LINES TERMINATED BY '
'
            IGNORE 1 LINES;
            , parameters: None
[2022-11-19T12:27:43.835+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/mysql/operators/mysql.py", line 86, in execute
    hook.run(self.sql, autocommit=self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 295, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 320, in _run_command
    cur.execute(sql_statement)
  File "/home/airflow/.local/lib/python3.7/site-packages/MySQLdb/cursors.py", line 206, in execute
    res = self._query(query)
  File "/home/airflow/.local/lib/python3.7/site-packages/MySQLdb/cursors.py", line 319, in _query
    db.query(q)
  File "/home/airflow/.local/lib/python3.7/site-packages/MySQLdb/connections.py", line 254, in query
    _mysql.connection.query(self, query)
MySQLdb.OperationalError: (1290, 'The MySQL server is running with the --secure-file-priv option so it cannot execute this statement')
[2022-11-19T12:27:44.491+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=Call_Center_ETL_DAG, task_id=load_data_to_staging_call_table, execution_date=20221118T000000, start_date=20221119T122714, end_date=20221119T122744
[2022-11-19T12:27:45.100+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 91 for task load_data_to_staging_call_table ((1290, 'The MySQL server is running with the --secure-file-priv option so it cannot execute this statement'); 651)
[2022-11-19T12:27:45.499+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2022-11-19T12:27:46.829+0000] {taskinstance.py:2623} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-11-20T00:39:24.846+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [queued]>
[2022-11-20T00:39:24.934+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [queued]>
[2022-11-20T00:39:24.935+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-11-20T00:39:24.937+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2022-11-20T00:39:24.938+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-11-20T00:39:25.022+0000] {taskinstance.py:1383} INFO - Executing <Task(MySqlOperator): load_data_to_staging_call_table> on 2022-11-18 00:00:00+00:00
[2022-11-20T00:39:25.062+0000] {standard_task_runner.py:55} INFO - Started process 3280 to run task
[2022-11-20T00:39:25.076+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'Call_Center_ETL_DAG', 'load_data_to_staging_call_table', 'scheduled__2022-11-18T00:00:00+00:00', '--job-id', '121', '--raw', '--subdir', 'DAGS_FOLDER/call_center_dag.py', '--cfg-path', '/tmp/tmp3jyb4mrk']
[2022-11-20T00:39:25.092+0000] {standard_task_runner.py:83} INFO - Job 121: Subtask load_data_to_staging_call_table
[2022-11-20T00:39:25.407+0000] {task_command.py:376} INFO - Running <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [running]> on host 9eba6bc17a61
[2022-11-20T00:39:25.647+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Abdelrhman Yassein
AIRFLOW_CTX_DAG_ID=Call_Center_ETL_DAG
AIRFLOW_CTX_TASK_ID=load_data_to_staging_call_table
AIRFLOW_CTX_EXECUTION_DATE=2022-11-18T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-18T00:00:00+00:00
[2022-11-20T00:39:25.650+0000] {mysql.py:84} INFO - Executing: 
            LOAD DATA LOCAL INFILE '/opt/***/data/CallCenter.csv'
            INTO TABLE staging_call
            COLUMNS TERMINATED BY ','
            OPTIONALLY ENCLOSED BY '"'
            ESCAPED BY '"'
            LINES TERMINATED BY '
'
            IGNORE 1 LINES;
            
[2022-11-20T00:39:25.665+0000] {base.py:71} INFO - Using connection ID 'mysql_conn_id' for task execution.
[2022-11-20T00:39:25.708+0000] {sql.py:315} INFO - Running statement: 
            LOAD DATA LOCAL INFILE '/opt/***/data/CallCenter.csv'
            INTO TABLE staging_call
            COLUMNS TERMINATED BY ','
            OPTIONALLY ENCLOSED BY '"'
            ESCAPED BY '"'
            LINES TERMINATED BY '
'
            IGNORE 1 LINES;
            , parameters: None
[2022-11-20T00:39:25.713+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/mysql/operators/mysql.py", line 86, in execute
    hook.run(self.sql, autocommit=self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 295, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 320, in _run_command
    cur.execute(sql_statement)
  File "/home/airflow/.local/lib/python3.7/site-packages/MySQLdb/cursors.py", line 206, in execute
    res = self._query(query)
  File "/home/airflow/.local/lib/python3.7/site-packages/MySQLdb/cursors.py", line 319, in _query
    db.query(q)
  File "/home/airflow/.local/lib/python3.7/site-packages/MySQLdb/connections.py", line 254, in query
    _mysql.connection.query(self, query)
MySQLdb.OperationalError: (3948, 'Loading local data is disabled; this must be enabled on both the client and server sides')
[2022-11-20T00:39:25.728+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=Call_Center_ETL_DAG, task_id=load_data_to_staging_call_table, execution_date=20221118T000000, start_date=20221120T003924, end_date=20221120T003925
[2022-11-20T00:39:25.757+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 121 for task load_data_to_staging_call_table ((3948, 'Loading local data is disabled; this must be enabled on both the client and server sides'); 3280)
[2022-11-20T00:39:25.787+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2022-11-20T00:39:25.837+0000] {taskinstance.py:2623} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-11-20T00:41:42.851+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [queued]>
[2022-11-20T00:41:42.907+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [queued]>
[2022-11-20T00:41:42.908+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-11-20T00:41:42.912+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2022-11-20T00:41:42.914+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-11-20T00:41:43.058+0000] {taskinstance.py:1383} INFO - Executing <Task(MySqlOperator): load_data_to_staging_call_table> on 2022-11-18 00:00:00+00:00
[2022-11-20T00:41:43.077+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'Call_Center_ETL_DAG', 'load_data_to_staging_call_table', 'scheduled__2022-11-18T00:00:00+00:00', '--job-id', '130', '--raw', '--subdir', 'DAGS_FOLDER/call_center_dag.py', '--cfg-path', '/tmp/tmpuwhavs7i']
[2022-11-20T00:41:43.080+0000] {standard_task_runner.py:55} INFO - Started process 3390 to run task
[2022-11-20T00:41:43.082+0000] {standard_task_runner.py:83} INFO - Job 130: Subtask load_data_to_staging_call_table
[2022-11-20T00:41:43.302+0000] {task_command.py:376} INFO - Running <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [running]> on host 9eba6bc17a61
[2022-11-20T00:41:43.928+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Abdelrhman Yassein
AIRFLOW_CTX_DAG_ID=Call_Center_ETL_DAG
AIRFLOW_CTX_TASK_ID=load_data_to_staging_call_table
AIRFLOW_CTX_EXECUTION_DATE=2022-11-18T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-18T00:00:00+00:00
[2022-11-20T00:41:43.935+0000] {mysql.py:84} INFO - Executing: 
            LOAD DATA LOCAL INFILE '/opt/***/data/CallCenter.csv'
            INTO TABLE staging_call
            COLUMNS TERMINATED BY ','
            OPTIONALLY ENCLOSED BY '"'
            ESCAPED BY '"'
            LINES TERMINATED BY '
'
            IGNORE 1 LINES;
            
[2022-11-20T00:41:43.988+0000] {base.py:71} INFO - Using connection ID 'mysql_conn_id' for task execution.
[2022-11-20T00:41:44.082+0000] {sql.py:315} INFO - Running statement: 
            LOAD DATA LOCAL INFILE '/opt/***/data/CallCenter.csv'
            INTO TABLE staging_call
            COLUMNS TERMINATED BY ','
            OPTIONALLY ENCLOSED BY '"'
            ESCAPED BY '"'
            LINES TERMINATED BY '
'
            IGNORE 1 LINES;
            , parameters: None
[2022-11-20T00:41:44.090+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/mysql/operators/mysql.py", line 86, in execute
    hook.run(self.sql, autocommit=self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 295, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 320, in _run_command
    cur.execute(sql_statement)
  File "/home/airflow/.local/lib/python3.7/site-packages/MySQLdb/cursors.py", line 206, in execute
    res = self._query(query)
  File "/home/airflow/.local/lib/python3.7/site-packages/MySQLdb/cursors.py", line 319, in _query
    db.query(q)
  File "/home/airflow/.local/lib/python3.7/site-packages/MySQLdb/connections.py", line 254, in query
    _mysql.connection.query(self, query)
MySQLdb.OperationalError: (3948, 'Loading local data is disabled; this must be enabled on both the client and server sides')
[2022-11-20T00:41:44.113+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=Call_Center_ETL_DAG, task_id=load_data_to_staging_call_table, execution_date=20221118T000000, start_date=20221120T004142, end_date=20221120T004144
[2022-11-20T00:41:44.163+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 130 for task load_data_to_staging_call_table ((3948, 'Loading local data is disabled; this must be enabled on both the client and server sides'); 3390)
[2022-11-20T00:41:44.224+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2022-11-20T00:41:44.449+0000] {taskinstance.py:2623} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-11-20T13:11:12.182+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [queued]>
[2022-11-20T13:11:12.242+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [queued]>
[2022-11-20T13:11:12.246+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-11-20T13:11:12.251+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2022-11-20T13:11:12.293+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-11-20T13:11:12.377+0000] {taskinstance.py:1383} INFO - Executing <Task(MySqlOperator): load_data_to_staging_call_table> on 2022-11-18 00:00:00+00:00
[2022-11-20T13:11:12.399+0000] {standard_task_runner.py:55} INFO - Started process 715 to run task
[2022-11-20T13:11:12.422+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'Call_Center_ETL_DAG', 'load_data_to_staging_call_table', 'scheduled__2022-11-18T00:00:00+00:00', '--job-id', '151', '--raw', '--subdir', 'DAGS_FOLDER/call_center_dag.py', '--cfg-path', '/tmp/tmplhcep274']
[2022-11-20T13:11:12.424+0000] {standard_task_runner.py:83} INFO - Job 151: Subtask load_data_to_staging_call_table
[2022-11-20T13:11:12.640+0000] {task_command.py:376} INFO - Running <TaskInstance: Call_Center_ETL_DAG.load_data_to_staging_call_table scheduled__2022-11-18T00:00:00+00:00 [running]> on host 9eba6bc17a61
[2022-11-20T13:11:13.027+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Abdelrhman Yassein
AIRFLOW_CTX_DAG_ID=Call_Center_ETL_DAG
AIRFLOW_CTX_TASK_ID=load_data_to_staging_call_table
AIRFLOW_CTX_EXECUTION_DATE=2022-11-18T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-11-18T00:00:00+00:00
[2022-11-20T13:11:13.029+0000] {mysql.py:84} INFO - Executing: 
    
            SET GLOBAL local_infile=1;
            LOAD DATA LOCAL INFILE '/opt/***/data/CallCenter.csv'
            INTO TABLE staging_call
            COLUMNS TERMINATED BY ','
            OPTIONALLY ENCLOSED BY '"'
            ESCAPED BY '"'
            LINES TERMINATED BY '
'
            IGNORE 1 LINES;
            
[2022-11-20T13:11:13.078+0000] {base.py:71} INFO - Using connection ID 'mysql_conn_id' for task execution.
[2022-11-20T13:11:13.273+0000] {sql.py:315} INFO - Running statement: 
    
            SET GLOBAL local_infile=1;
            LOAD DATA LOCAL INFILE '/opt/***/data/CallCenter.csv'
            INTO TABLE staging_call
            COLUMNS TERMINATED BY ','
            OPTIONALLY ENCLOSED BY '"'
            ESCAPED BY '"'
            LINES TERMINATED BY '
'
            IGNORE 1 LINES;
            , parameters: None
[2022-11-20T13:11:13.278+0000] {sql.py:324} INFO - Rows affected: 0
[2022-11-20T13:11:20.073+0000] {taskinstance.py:1406} INFO - Marking task as SUCCESS. dag_id=Call_Center_ETL_DAG, task_id=load_data_to_staging_call_table, execution_date=20221118T000000, start_date=20221120T131112, end_date=20221120T131120
[2022-11-20T13:11:20.217+0000] {local_task_job.py:159} INFO - Task exited with return code 0
[2022-11-20T13:11:20.394+0000] {taskinstance.py:2623} INFO - 1 downstream tasks scheduled from follow-on schedule check
